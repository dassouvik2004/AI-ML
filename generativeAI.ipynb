{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMP9ipUGKVojjtiqX0VE+Fb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dassouvik2004/AI-ML/blob/main/generativeAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OykJSNSfjDw_",
        "outputId": "a6c0e4a1-2e70-4ad4-a194-b80a461c6e3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=40) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When I was happy, I see people coming from all walks of life and I don't know if they're going to make the same type of journey. People that are smart, they get it. But I can see people making that journey.\n",
            "\n",
            "\"That's the way it's going to be, I'm not sure what's going to happen. I'm not sure what's going to be better. And I'm not sure if it'll be better or worse. I'm not sure, just that sometimes you don't want to live any longer.\"\n",
            "\n",
            "Golf is an important part of life, but it can also be a distraction, he said.\n",
            "\n",
            "\"There are a lot of distractions in life. When I'm home, I'm not able to sit down and watch TV. And when I'm out there, I'm not able to go to the gym because I'm so tired. If you're in the club, you're not able to go to the gym. It's just a distraction. It's just a lot of distractions.\"\n",
            "\n",
            "In his book, \"The Golf Experience,\" Gudmundsson also writes about the \"game of golf,\" and the golfers that he sees. He talked about playing the game as a spectator, and how they can help\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\",model=\"gpt2\")\n",
        "\n",
        "result = generator(\"When I was happy, I see\",max_length=40,num_return_sequences=1)\n",
        "print(result[0]['generated_text'])"
      ]
    }
  ]
}